from token      import Token
from typing     import List

class Lexer:

    # Converts a stream of characters into a stream of tokens.
    def tokenize(self, text: str) -> List[Token]:
        pass
